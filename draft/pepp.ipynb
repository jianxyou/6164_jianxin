{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PEPit import PEP\n",
    "from PEPit.functions import SmoothStronglyConvexFunction\n",
    "\n",
    "def alt_gda_pep(mu, L, n_steps):\n",
    "    problem = PEP()\n",
    "\n",
    "    # 定义强凸强凹函数f(x,y)\n",
    "    func_x = problem.declare_function(SmoothStronglyConvexFunction, L=L, mu=mu)\n",
    "    func_y = problem.declare_function(SmoothStronglyConvexFunction, L=L, mu=mu)\n",
    "\n",
    "    # 定义起始点\n",
    "    x0 = problem.set_initial_point()\n",
    "    y0 = problem.set_initial_point()\n",
    "\n",
    "    # 定义最优点 (Nash Equilibrium)\n",
    "    xs = func_x.stationary_point()\n",
    "    ys = func_y.stationary_point()\n",
    "    # 初始误差\n",
    "    problem.set_initial_condition((x0 - xs)**2 + (y0 - ys)**2 <= 1)\n",
    "\n",
    "    # 交替梯度下降上升迭代 (Alt-GDA)\n",
    "    x, y = x0, y0\n",
    "    eta = 1 / (2 * L)  # 步长，根据理论设置\n",
    "    for _ in range(n_steps):\n",
    "        x = x - eta * func_x.gradient(x)\n",
    "        y = y + eta * func_y.gradient(y)\n",
    "\n",
    "    # 设置目标为最优点的距离\n",
    "    problem.set_performance_metric((x - xs)**2 + (y - ys)**2)\n",
    "\n",
    "    # 求解PEP问题\n",
    "    pep_value = problem.solve(verbose=0)\n",
    "\n",
    "    return pep_value\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kappas = np.logspace(1, 3)  # 条件数区间\n",
    "    complexities = []\n",
    "    n_steps = 10  # 固定迭代步数\n",
    "\n",
    "    for kappa in kappas:\n",
    "        mu = 0.1\n",
    "        L = kappa * mu\n",
    "        complexity = alt_gda_pep(mu, L, n_steps)\n",
    "        complexities.append(complexity)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.loglog(kappas, complexities, 'o-', label='Alt-GDA worst-case complexity (PEP)')\n",
    "    plt.xlabel('Condition number κ')\n",
    "    plt.ylabel('Worst-case complexity')\n",
    "    plt.grid(True, which='both', ls='--', alpha=0.4)\n",
    "    plt.legend()\n",
    "    plt.title('Alt-GDA complexity via PEP')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 用线性回归估计log-log斜率，验证复杂度指数\n",
    "    slope, intercept = np.polyfit(np.log(kappas), np.log(complexities), 1)\n",
    "    print(f\"估计复杂度为O(kappa^{slope:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Point' object has no attribute 'decompose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m L_y)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Alt-GDA更新规则：\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m x0, y0 \u001b[38;5;241m=\u001b[39m \u001b[43mz0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompose\u001b[49m()\n\u001b[1;32m     27\u001b[0m grad_x0, grad_y0 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mgradient(z0)\u001b[38;5;241m.\u001b[39mdecompose()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Alt-GDA第一步 (x 更新)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Point' object has no attribute 'decompose'"
     ]
    }
   ],
   "source": [
    "from PEPit import PEP\n",
    "from PEPit.operators import LipschitzStronglyMonotoneOperator\n",
    "\n",
    "# 设置问题参数\n",
    "mu_x, mu_y = 0.1, 0.1\n",
    "L_x, L_y = 1, 1\n",
    "L_xy = 1\n",
    "\n",
    "# Lipschitz 常数估计 (可更精细)\n",
    "L = max(L_x, L_y, L_xy)\n",
    "\n",
    "# 初始化PEP问题\n",
    "problem = PEP()\n",
    "\n",
    "# 声明Lipschitz单调算子\n",
    "F = problem.declare_function(LipschitzStronglyMonotoneOperator, L=L, mu = mu_x)\n",
    "\n",
    "# 初始化点 z0 = (x0, y0)\n",
    "z0 = problem.set_initial_point()\n",
    "\n",
    "# 设置步长 (来自论文推荐)\n",
    "alpha = 1 / (2 * L_x)\n",
    "beta = 1 / (2 * L_y)\n",
    "\n",
    "# Alt-GDA更新规则：\n",
    "x0, y0 = z0.decompose()\n",
    "grad_x0, grad_y0 = F.gradient(z0).decompose()\n",
    "\n",
    "# Alt-GDA第一步 (x 更新)\n",
    "x1 = x0 - alpha * grad_x0\n",
    "\n",
    "# Alt-GDA第二步 (y 更新，注意这里用了 x1 而非 x0)\n",
    "z_half = problem.set_point((x1, y0))\n",
    "_, grad_y_half = F.gradient(z_half).decompose()\n",
    "y1 = y0 - beta * grad_y_half\n",
    "\n",
    "# 组合回 z1\n",
    "z1 = problem.set_point((x1, y1))\n",
    "\n",
    "# 设置收敛性能度量为算子范数的平方\n",
    "problem.set_performance_metric(F.gradient(z1)**2)\n",
    "\n",
    "# 求解PEP问题\n",
    "pep_value = problem.solve(verbose=True)\n",
    "\n",
    "print(f'Worst-case performance (operator norm squared): {pep_value:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m L_y)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Alt-GDA 更新\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m grad_x0, _ \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m-\u001b[39m alpha \u001b[38;5;241m*\u001b[39m grad_x0\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 第二步更新需要用到新创建的点 (x1,y0)\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PEPit/function.py:757\u001b[0m, in \u001b[0;36mFunction.gradient\u001b[0;34m(self, point, name)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient\u001b[39m(\u001b[38;5;28mself\u001b[39m, point, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    742\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;124;03m    Return the gradient (or a subgradient) of this :class:`Function` evaluated at `point`.\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    754\u001b[0m \n\u001b[1;32m    755\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PEPit/function.py:776\u001b[0m, in \u001b[0;36mFunction.subgradient\u001b[0;34m(self, point, name)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;124;03mReturn a subgradient of this :class:`Function` evaluated at `point`.\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    772\u001b[0m \n\u001b[1;32m    773\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;66;03m# Verify point is a Point\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(point, Point)\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# Call oracle but only return the gradient\u001b[39;00m\n\u001b[1;32m    779\u001b[0m g, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle(point)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PEPit import PEP\n",
    "from PEPit.operators import LipschitzStronglyMonotoneOperator\n",
    "\n",
    "# 设置问题参数\n",
    "mu_x, mu_y = 0.1, 0.1\n",
    "L_x, L_y = 1, 1\n",
    "L_xy = 1\n",
    "L = max(L_x, L_y, L_xy)\n",
    "\n",
    "# 初始化PEP问题\n",
    "problem = PEP()\n",
    "\n",
    "# 声明Lipschitz单调算子\n",
    "F = problem.declare_function(LipschitzStronglyMonotoneOperator, L=L, mu = mu_x)\n",
    "\n",
    "# 初始化点(x0, y0)\n",
    "x0 = problem.set_initial_point()\n",
    "y0 = problem.set_initial_point()\n",
    "z0 = (x0, y0)\n",
    "\n",
    "# 设置步长 (Alt-GDA 推荐值)\n",
    "alpha = 1 / (2 * L_x)\n",
    "beta = 1 / (2 * L_y)\n",
    "\n",
    "# Alt-GDA 更新\n",
    "grad_x0, _ = F.gradient(z0)\n",
    "x1 = x0 - alpha * grad_x0\n",
    "\n",
    "z_half = problem.set_point((x1, y0))\n",
    "_, grad_y_half = F.gradient(z_half)\n",
    "y1 = y0 - beta * grad_y_half\n",
    "\n",
    "# 更新后的新点\n",
    "z1 = problem.set_point((x1, y1))\n",
    "\n",
    "# 设置性能度量 (最常用的是算子范数平方)\n",
    "problem.set_performance_metric(F.gradient(z1)**2)\n",
    "\n",
    "# 求解PEP问题\n",
    "pep_value = problem.solve(verbose=True)\n",
    "\n",
    "print(f'Worst-case performance (operator norm squared): {pep_value:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
